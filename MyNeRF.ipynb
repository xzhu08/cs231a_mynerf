{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22269a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import imageio\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485563d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9092fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a0fbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveModel(file_path, params, losses, psnrs):\n",
    "    if not os.path.exists(file_path):\n",
    "        os.makedirs(file_path)\n",
    "        \n",
    "    params['nerf'].save_weights(file_path)\n",
    "    \n",
    "    saved_params = {k : params[k] for k in params if type(params[k]) in {float, int, bool, str}}\n",
    "    data = {}\n",
    "    losses = [float(loss) for loss in losses]\n",
    "    psnrs = [float(psnr) for psnr in psnrs]\n",
    "    data['params'] = saved_params\n",
    "    data['losses'] = losses\n",
    "    data['psnrs'] = psnrs\n",
    "    with open(os.path.join(file_path, 'params.json'), 'w') as json_file:\n",
    "        json.dump(data, json_file)\n",
    "\n",
    "def LoadModel(file_path):\n",
    "    with open(os.path.join(file_path, 'params.json'), 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    \n",
    "    losses = data['losses']\n",
    "    psnrs = data['psnrs']\n",
    "    params = data['params']\n",
    "    if params['use_encoder']:\n",
    "        params['pos_encoder'] = lambda x : PositionEncoder(x, 10)\n",
    "        params['dir_encoder'] = lambda x : PositionEncoder(x, 4)\n",
    "        params['nerf'] = BuildNeRF(63, 27)\n",
    "    else:\n",
    "        params['nerf'] = BuildNeRF(3, 3)\n",
    "        \n",
    "    params['nerf'].load_weights(file_path)\n",
    "    return params, losses, psnrs\n",
    "    \n",
    "def LoadData(data_path, json_name, width, height, params = None):\n",
    "    with open(os.path.join(data_path, json_name), 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "        images = []\n",
    "        poses = []\n",
    "    \n",
    "        for frame in data['frames']:\n",
    "            img_path = os.path.join(data_path, frame['file_path'] + '.png')\n",
    "            images.append(imageio.imread(img_path))\n",
    "            poses.append(np.array(frame['transform_matrix']))\n",
    "        images = (np.array(images) / 255.).astype(np.float32)\n",
    "        poses = np.array(poses).astype(np.float32)\n",
    "    \n",
    "        images = tf.compat.v1.image.resize_area(images, [height, width]).numpy()\n",
    "        camera_angle_x = float(data['camera_angle_x'])\n",
    "        \n",
    "        if params is not None:\n",
    "            params['focal_length'] = .5 * width / np.tan(.5 * camera_angle_x)\n",
    "        \n",
    "    return images, poses \n",
    "    \n",
    "def PositionEncoder(x, L):\n",
    "    encoded_x = [x]\n",
    "    for i in range(L):\n",
    "        for func in [tf.sin, tf.cos]:\n",
    "            encoded_x.append(func(2.0 ** i * x))\n",
    "    return tf.concat(encoded_x, axis = -1)\n",
    "\n",
    "def GenerateRays(width, height, focal_length, trans_mat):  \n",
    "    # Generate rays in camera frame.\n",
    "    i, j = tf.meshgrid(\\\n",
    "        tf.range(width, dtype = tf.float32),\\\n",
    "        tf.range(height, dtype = tf.float32),\\\n",
    "        indexing = 'xy'\\\n",
    "    )\n",
    "    \n",
    "    # The depth from pinhole to camera plane is 1.\n",
    "    ray_cam = tf.stack(\\\n",
    "        [\\\n",
    "            (-0.5 * width + i) / focal_length,\\\n",
    "            (0.5 * height - j) / focal_length,\\\n",
    "            -tf.ones_like(i)\\\n",
    "        ],\\\n",
    "        axis = -1\\\n",
    "    )\n",
    "    \n",
    "    # Transfer the rays from camera frame to world frame.\n",
    "    ray_dir = tf.reduce_sum(ray_cam[..., None, :] * trans_mat[:3, :3], axis = -1)\n",
    "    ray_ori = tf.broadcast_to(trans_mat[:3, -1], tf.shape(ray_dir))\n",
    "    \n",
    "    return ray_ori, ray_dir\n",
    "\n",
    "def GetPdfFromWeights(weights, bins, n_samples):\n",
    "    # Get pdf\n",
    "    weights += 1e-5\n",
    "    pdf = weights / tf.reduce_sum(weights, -1, keepdims=True)\n",
    "    cdf = tf.cumsum(pdf, -1)\n",
    "    cdf = tf.concat([tf.zeros_like(cdf[..., :1]), cdf], -1)\n",
    "\n",
    "    # Take uniform samples\n",
    "    u = tf.random.uniform(list(cdf.shape[:-1]) + [n_samples])\n",
    "\n",
    "    # Invert CDF\n",
    "    inds = tf.searchsorted(cdf, u, side='right')\n",
    "    below = tf.maximum(0, inds-1)\n",
    "    above = tf.minimum(cdf.shape[-1]-1, inds)\n",
    "    inds_g = tf.stack([below, above], -1)\n",
    "    cdf_g = tf.gather(cdf, inds_g, axis=-1, batch_dims=len(inds_g.shape)-2)\n",
    "    bins_g = tf.gather(bins, inds_g, axis=-1, batch_dims=len(inds_g.shape)-2)\n",
    "\n",
    "    denom = (cdf_g[..., 1]-cdf_g[..., 0])\n",
    "    denom = tf.where(denom < 1e-5, tf.ones_like(denom), denom)\n",
    "    t = (u-cdf_g[..., 0])/denom\n",
    "    samples = bins_g[..., 0] + t * (bins_g[..., 1]-bins_g[..., 0])\n",
    "\n",
    "    return samples\n",
    "\n",
    "def VolumeRender(ray_dir, z_vals, outputs):\n",
    "    # rendering equation:\n",
    "    #   res = sum^N_{i = 1} T_i x density_i x color_i\n",
    "    #   T_i = exp(-sum^i_{j=1} -alpha_j x t_j)\n",
    "    #   density_i = 1 - exp(-alpha_i x t_i)\n",
    "    \n",
    "    # Generate t_i\n",
    "    t = z_vals[..., 1:] - z_vals[..., :-1]\n",
    "    # The last time piece is infity.\n",
    "    t = tf.concat([t, tf.broadcast_to([1e10], t[...,:1].shape)], axis = -1)\n",
    "    # Scale the time with the norm of each ray direction.\n",
    "    t = t * tf.linalg.norm(ray_dir[..., None, :], axis = -1)\n",
    "    \n",
    "    # Get color_i from outputs (map outputs[..., :3] in 0 to 1).\n",
    "    rgb = tf.math.sigmoid(outputs[..., :3])\n",
    "    \n",
    "    # Get alpha_i\n",
    "    alpha = tf.nn.relu(outputs[..., 3])\n",
    "    \n",
    "    # Estimate density_i.\n",
    "    density = 1.0 - tf.exp(-alpha * t)\n",
    "    \n",
    "    # Estimate T_i\n",
    "    T = tf.math.cumprod(1.0 - density +  1e-10, axis = -1, exclusive = True)\n",
    "    \n",
    "    # Get weight_i = T_i x density_i\n",
    "    weight = density * T\n",
    "    \n",
    "    # Weighted sum along each ray.\n",
    "    res = tf.reduce_sum(weight[..., None] * rgb, axis = -2)\n",
    "    \n",
    "    return res, weight\n",
    "    \n",
    "def BuildNeRF(n_pos, n_dir, n_layers = 8, n_neurons = 256):\n",
    "    \n",
    "    # Seperate the inputs into position and direction.\n",
    "    inputs = tf.keras.Input(shape=(n_pos + n_dir))\n",
    "    inputs_pos, inputs_dir = tf.split(inputs, [n_pos, n_dir], axis = -1)\n",
    "    inputs_pos.set_shape([None, n_pos])\n",
    "    inputs_dir.set_shape([None, n_dir])\n",
    "    \n",
    "    # Construct the Network.\n",
    "    # 1. Build n_layers MLP with ReLU as activation layer.\n",
    "    ReLU = tf.keras.layers.ReLU()\n",
    "    MLP = lambda input_features, W, act :\\\n",
    "        tf.keras.layers.Dense(\\\n",
    "            W, activation = act\\\n",
    "        )(input_features)\n",
    "\n",
    "    outputs = inputs_pos\n",
    "    for i_layer in range(n_layers):\n",
    "        outputs = MLP(outputs, n_neurons, ReLU)\n",
    "        # Concatenate the input position to output features after the middle layer\n",
    "        if i_layer == n_layers // 2:\n",
    "            outputs = tf.concat([inputs_pos, outputs], axis = -1)\n",
    "            \n",
    "    # 2. Generate alpha and input features for direction.\n",
    "    alpha = MLP(outputs, 1, None)\n",
    "    bottleneck = MLP(outputs, n_neurons, None)\n",
    "    \n",
    "    # 3. Concatenate the input views with output features to generate final results\n",
    "    outputs = tf.concat([bottleneck, inputs_dir], axis = -1)\n",
    "    outputs = MLP(outputs, n_neurons // 2, ReLU)\n",
    "    outputs = MLP(outputs, 3, None)\n",
    "    outputs = tf.concat([outputs, alpha], axis = -1)\n",
    "    \n",
    "    return tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "def RenderPoints(pos, view_dir, params):\n",
    "    pos_flat = tf.reshape(pos, [-1, pos.shape[-1]])\n",
    "    dirs = tf.broadcast_to(view_dir[:, None], pos.shape)\n",
    "    dirs_flat = tf.reshape(dirs, [-1, dirs.shape[-1]])\n",
    "        \n",
    "    inputs = None\n",
    "    if params['use_encoder']:\n",
    "        pos_encoder = params['pos_encoder']\n",
    "        dir_encoder = params['dir_encoder']\n",
    "        inputs = tf.concat([pos_encoder(pos_flat), dir_encoder(dirs_flat)], axis = -1)\n",
    "    else:\n",
    "        inputs = tf.concat([pos_flat, dirs_flat], axis = -1)\n",
    "        \n",
    "    batch_size = params['point_batch_size']\n",
    "    outputs = []\n",
    "    nerf = params['nerf']\n",
    "    for i in range(0, pos_flat.shape[0], batch_size):\n",
    "        outputs.append(nerf(inputs[i:i+batch_size]))\n",
    "        \n",
    "    outputs = tf.concat(outputs, axis = 0)\n",
    "    outputs = tf.reshape(outputs, list(pos.shape[:-1]) + [outputs.shape[-1]])\n",
    "    return outputs\n",
    "\n",
    "def RenderRays(rays, params):\n",
    "    n_rays = rays.shape[0]\n",
    "    \n",
    "    ray_ori, ray_dir, view_dir = rays[:, :3], rays[:, 3:6], rays[:, -3:]\n",
    "    \n",
    "    bounds = tf.reshape(rays[..., 6:8], [-1, 1, 2])\n",
    "    near, far = bounds[..., 0], bounds[..., 1] \n",
    "    \n",
    "    # Estimate the sampling time\n",
    "    n_samples = params['n_samples']\n",
    "    t = tf.linspace(0., 1., n_samples)\n",
    "    z_vals = near * (1 - t) + far * t\n",
    "    z_vals = tf.broadcast_to(z_vals, [n_rays, n_samples])\n",
    "    \n",
    "    # Pertub sampling time\n",
    "    mids = .5 * (z_vals[..., 1:] + z_vals[..., :-1])\n",
    "    upper = tf.concat([mids, z_vals[..., -1:]], -1)\n",
    "    lower = tf.concat([z_vals[..., :1], mids], -1)\n",
    "    \n",
    "    t_rand = tf.random.uniform(z_vals.shape)\n",
    "    z_vals = lower + (upper - lower) * t_rand\n",
    "    \n",
    "    pos = ray_ori[..., None, :] + ray_dir[..., None, :] * z_vals[..., :, None]\n",
    "    \n",
    "    # Render Points\n",
    "    outputs = RenderPoints(pos, view_dir, params)\n",
    "    res, weight = VolumeRender(ray_dir, z_vals, outputs)\n",
    "    \n",
    "    # Resampling according to the rendered results\n",
    "    if params['importance_sampling']:\n",
    "        res_0, weight_0 = res, weight\n",
    "\n",
    "        # Obtain additional integration times to evaluate based on the weights\n",
    "        # assigned to colors in the coarse model.\n",
    "        z_vals_mid = .5 * (z_vals[..., 1:] + z_vals[..., :-1])\n",
    "        z_samples = GetPdfFromWeights(\n",
    "            weight[..., 1:-1], z_vals_mid, n_samples)\n",
    "        z_samples = tf.stop_gradient(z_samples)\n",
    "\n",
    "        # Obtain all points to evaluate color, density at.\n",
    "        z_vals = tf.sort(tf.concat([z_vals, z_samples], -1), -1)\n",
    "        pos = ray_ori[..., None, :] + ray_dir[..., None, :] * z_vals[..., :, None]\n",
    "\n",
    "        # Run network with new samples.\n",
    "        outputs = RenderPoints(pos, view_dir, params)\n",
    "        res, _ = VolumeRender(ray_dir, z_vals, outputs)\n",
    "    \n",
    "    return res\n",
    "\n",
    "def RenderImage(width, height, pose, params):\n",
    "    focal_length = params['focal_length']\n",
    "    \n",
    "    # Get rays from current camera settings.\n",
    "    ray_ori, ray_dir = GenerateRays(width, height, focal_length, pose)\n",
    "    \n",
    "    # Get normalized view ray directions.\n",
    "    view_dir = ray_dir\n",
    "    view_dir = ray_dir / tf.linalg.norm(ray_dir, axis = -1, keepdims = True)\n",
    "    \n",
    "    # Flat the input\n",
    "    ray_ori = tf.cast(tf.reshape(ray_ori, [-1, 3]), dtype = tf.float32)\n",
    "    ray_dir = tf.cast(tf.reshape(ray_dir, [-1, 3]), dtype = tf.float32)\n",
    "    view_dir = tf.cast(tf.reshape(view_dir, [-1, 3]), dtype = tf.float32)\n",
    "    \n",
    "    near = params['near'] * tf.ones_like(ray_dir[..., :1])\n",
    "    far = params['far'] * tf.ones_like(ray_dir[..., :1])\n",
    "    \n",
    "    rays = tf.concat([ray_ori, ray_dir, near, far, view_dir], axis = -1)\n",
    "    \n",
    "    batch_size = params['ray_batch_size']\n",
    "    render_results = []\n",
    "    for i in range(0, rays.shape[0], batch_size):\n",
    "        render_results.append(\\\n",
    "            RenderRays(rays[i:i+batch_size], params)\\\n",
    "        )\n",
    "    return tf.reshape(tf.concat(render_results, axis = 0), [height, width, 3])\n",
    "\n",
    "def TrainNeRF(train_images, train_poses,test_image, test_pose, n_epochs, params):\n",
    "    nerf = params['nerf']\n",
    "\n",
    "    l_rate = params['learning_rate']\n",
    "    optimizer = tf.keras.optimizers.Adam(l_rate)\n",
    "    \n",
    "    height, width = train_images[0].shape[:2]\n",
    "    print(\"----------------Start Training----------------\")\n",
    "    print(\"W:{0}, H:{1}\".format(width, height))\n",
    "    for k in params:\n",
    "        if type(params[k]) in {int, float, str, bool}:\n",
    "            print('{0}: {1}'.format(k, params[k]))\n",
    "    \n",
    "    test_iternum = []\n",
    "    test_losses = []\n",
    "    test_psnrs = []\n",
    "    train_psnrs = []\n",
    "    avg_train_psnrs = []\n",
    "    for i in range(n_epochs):\n",
    "        # Random select an image to train the model.\n",
    "        img_i = np.random.randint(train_images.shape[0])\n",
    "        train_image = train_images[img_i]\n",
    "        train_pose = train_poses[img_i]\n",
    "        with tf.GradientTape() as tape:\n",
    "            predict = RenderImage(width, height, train_pose, params)\n",
    "            loss = tf.reduce_mean(tf.square(predict - train_image[...,:-1]))\n",
    "            train_psnr = -10. * tf.math.log(loss) / tf.math.log(10.)\n",
    "            train_psnrs.append(train_psnr)\n",
    "        gradients = tape.gradient(loss, nerf.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, nerf.trainable_variables))\n",
    "        print('-----------------epoch: {0} training loss: {1}------------'.format(i, loss), end = '\\r')\n",
    "        \n",
    "        if i % 25 == 0 and i > 0:\n",
    "            test_predict = RenderImage(width, height, test_pose, params)\n",
    "            test_loss = tf.reduce_mean(tf.square(test_predict - test_image[...,:-1]))\n",
    "            test_psnr = -10. * tf.math.log(test_loss) / tf.math.log(10.)\n",
    "            avg_train_psnrs.append(tf.reduce_mean(train_psnrs))\n",
    "            if len(train_psnrs) > train_images.shape[0]:\n",
    "                train_psnrs = []\n",
    "            \n",
    "            test_losses.append(test_loss)\n",
    "            test_psnrs.append(test_psnr)\n",
    "            test_iternum.append(i)\n",
    "            \n",
    "            plt.figure(figsize=(15,4))\n",
    "            plt.subplot(131)\n",
    "            plt.imshow(test_image)\n",
    "            plt.title(f'GT')\n",
    "            plt.subplot(132)\n",
    "            plt.imshow(test_predict)\n",
    "            plt.title(f'Iteration: {i}')\n",
    "            plt.subplot(133)\n",
    "            plt.plot(test_iternum, test_psnrs)\n",
    "            plt.title('PNSR')\n",
    "            plt.show()\n",
    "    return test_losses, test_psnrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c72e4a7",
   "metadata": {},
   "source": [
    "## Step 1.1 When First Run the Model (Skip Step 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8282f5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['nerf'] = BuildNeRF(63, 27)\n",
    "params['use_encoder'] = True\n",
    "params['ray_batch_size'] = 1024\n",
    "params['point_batch_size'] = 1024\n",
    "params['near'] = 2.0\n",
    "params['far'] = 6.0\n",
    "params['n_samples'] = 64\n",
    "params['pos_encoder'] = lambda x : PositionEncoder(x, 10)\n",
    "params['dir_encoder'] = lambda x : PositionEncoder(x, 4)\n",
    "params['importance_sampling'] = False\n",
    "params['learning_rate'] = 5e-4\n",
    "params['width'] = 50\n",
    "params['height'] = 50\n",
    "\n",
    "final_losses = []\n",
    "final_psnrs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d514efd",
   "metadata": {},
   "source": [
    "## Step 1.2 When You Want To Continue Running A Trained Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b325a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "params, final_losses, final_psnrs = LoadModel('./tank_nerf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a697d709",
   "metadata": {},
   "source": [
    "## Step 2 Load in Training And Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4077c17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/tank/'\n",
    "\n",
    "width, height = params['width'], params['height']\n",
    "train_images, train_poses = LoadData(data_path, 'transforms_train.json', width, height, params)\n",
    "test_images, test_poses = LoadData(data_path, 'transforms_test.json', width, height)\n",
    "\n",
    "test_id = np.random.randint(test_images.shape[0])\n",
    "test_image, test_pose = test_images[test_id], test_poses[test_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0a71df",
   "metadata": {},
   "source": [
    "## Step 3 Repeatly Run This Section To Train the Model With Different Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8228f48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params['learning_rate'] = 5e-4\n",
    "test_losses, test_psnrs = TrainNeRF(\\\n",
    "    train_images, train_poses, train_images[0], train_poses[0], 1000, params)\n",
    "final_losses += test_losses\n",
    "final_psnrs += test_psnrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311bd29b",
   "metadata": {},
   "source": [
    "## Step 4 Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490cbc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveModel('./tank_nerf', params, final_losses, final_psnrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03feca36",
   "metadata": {},
   "source": [
    "## Step 5 Generate Synthesis Scene of Test Poses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60a60f8",
   "metadata": {},
   "source": [
    "### 5.0 Estimate Average Test Psnrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30c5e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_psnrs = []\n",
    "for test_image, test_pose in zip(test_images, test_poses):\n",
    "    res = RenderImage(width, height, test_pose, params)\n",
    "    loss = tf.reduce_mean(res - test_image[...,:-1])\n",
    "    psnr = -10. * tf.math.log(loss) / tf.math.log(10.)\n",
    "    avg_psnrs.append(psnr)\n",
    "print(np.mean([psnr.numpy() for psnr in avg_psnrs if not np.isnan(psnr.numpy())]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3991dd78",
   "metadata": {},
   "source": [
    "### Step 5.1 Generate Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cb928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = './tank_test'\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "for i, test_pose in enumerate(test_poses):\n",
    "    #print('-------rendering {0}th image-------------\\r'.format(i))\n",
    "    res = RenderImage(width, height, test_pose, params)\n",
    "    imageio.imwrite(os.path.join(output_path, 'r_{0}.png'.format(i)), res.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021cb4d8",
   "metadata": {},
   "source": [
    "### 5.2 Generate Gif (Should First Run STep 5.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3c8ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = './tank_test'\n",
    "frames = []\n",
    "for filename in os.listdir(input_path):\n",
    "    if filename.split('.')[-1] == 'png':\n",
    "        frames.append(imageio.imread(os.path.join(input_path, filename)))\n",
    "imageio.mimsave(os.path.join(input_path, 'lego.gif'), frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761e2e03",
   "metadata": {},
   "source": [
    "### 5.3 Generate nxn pictures for paper results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927efc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = './lego_test'\n",
    "frames = []\n",
    "count = 0\n",
    "for filename in os.listdir(input_path):\n",
    "    if filename.split('.')[-1] == 'png':\n",
    "        frames.append(imageio.imread(os.path.join(input_path, filename)))\n",
    "        count += 1\n",
    "\n",
    "H = min(10, int(np.sqrt(count)))\n",
    "plt.figure(figsize = (H,H))\n",
    "for i in range(H*H):\n",
    "    plt.subplot(H,H,i+1)\n",
    "    plt.imshow(frames[i])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d3f4ee",
   "metadata": {},
   "source": [
    "### 5.4 Generate psnrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86493551",
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = params['width'], params['height']\n",
    "test_predict = RenderImage(width, height, test_pose, params)\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(131)\n",
    "plt.imshow(test_image)\n",
    "plt.title(f'GT')\n",
    "plt.subplot(132)\n",
    "plt.imshow(test_predict)\n",
    "plt.title(f'Iteration: 15k')\n",
    "plt.subplot(133)\n",
    "plt.plot(100 * np.arange(150), final_psnrs[:150])\n",
    "plt.title('PNSR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82202c39",
   "metadata": {},
   "source": [
    "## NeRF Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33fbb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_img_file = './nerf_graph.png'\n",
    "tf.keras.utils.plot_model(params['nerf'], to_file=dot_img_file, show_shapes=True, show_layer_names = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerf",
   "language": "python",
   "name": "nerf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
